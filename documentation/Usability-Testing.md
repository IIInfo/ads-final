We conducted user interviews with each of our hypothesized persona types (consumers, doctors, FDA administrators, senior citizens, advocacy groups) which were updated, expanded or removed based on the incoming user data. For instance, we originally had a doctor persona which was removed after several phone interviews with doctors because user data showed that they were not, in reality, a target audience. Based on our in-person user interviews in a LabCorp waiting room, our consumer persona was broken into two very different personas (Becca the label reader; Vic a non-reader). We conducted two rounds of usability testing (4-5 participants in each round) on wireframes created in Axure with both Beccas and Vics. These were moderated, in-person usability test sessions where the participants pulled up our wireframes and walked through unstructured impressions on layout, navigation, content and interaction. We made significant changes based on both preference and behavioral data from each round of this small-scale usability testing.

We conducted phone-based user interviews with doctors we knew to understand their process in deciding on what medications to prescribe.  They told us about sites they were already using such as UpToDate which worked extremely well for their needs, and because of those interviews we decided that doctors were actually not our target audience, so we went back to the other audiences to refine them further. For general public consumers, we wanted to target health-conscious people of all ages and backgrounds so we chose to go to a LabCorp waiting room in order to chat with users waiting for bloodwork about their goals and needs in a system with medical data. 

![usab testing labcorp front desk](https://cloud.githubusercontent.com/assets/13038047/8505393/fbc73c6e-21b1-11e5-9c84-61767058d0bc.jpg)
![usab testing labcorp participants](https://cloud.githubusercontent.com/assets/13038047/8505394/fbd0f632-21b1-11e5-9089-dd816cc66fe7.jpg)

To understand the geriatric community, we spoke to two senior citizens by phone. We also spoke to two members of the Board of Directors of a local assisted living community, Vantage House: 

![vantage house](https://cloud.githubusercontent.com/assets/13038047/8505405/7ac43ca6-21b2-11e5-835c-a2ff2307e5f5.jpg)

For the advocacy group persona, we phoned the founder of the Hashimotoâ€™s 411 group (which one of our user interviews referenced), and also spoke to two members of the group. Our in-person, moderated usability testing also provided qualitative behavioral data on user goals to be incorporated into the wireframes as well as personas. 

Our user interviews impacted not only our personas, but also our user stories, journey maps, and wireframes. Ultimately these interviews guided what product we were building. We found out that about half of the people we spoke to read labels, and of those people nearly all of them feel mistrusting of the label alone, and for good reason!  Of the top adverse events reported, only a fraction makes it onto medicine labels. To do anything about this big honkin' problem, we needed better data.  And who better to help us with that than the people who need it -- health conscious general public, advocacy groups, etc. Everyone wants to know about side effects, and a small fraction of these people are willing to help make labels more accurate. With crowdsourcing, even a small fraction of do-gooders can make a big difference. Therefore, the goal of our website is ultimately to perform a gap analysis between adverse events data and label data, using crowdsourcing to help give us the proper data to help FDA administrators make drug labels more accurate. 

