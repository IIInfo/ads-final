![human_centered_design_v1](https://cloud.githubusercontent.com/assets/12210910/8392525/11940b48-1cb3-11e5-8fe7-3f79af83f7c9.png)

## Learning about the Data
We kicked off the first day with icebreakers and a data show-and-tell session where data scientist subject matter experts walked us through the data and discussed with the team the types of data we had to work with. We discussed the different sets of data and wondered if it was a possibility to could combine multiple sets of data into one valuable product in a unique way that would offer a valuable differentiator to target users. 

![graph](https://cloud.githubusercontent.com/assets/13038047/8505206/dfd97a8e-21ad-11e5-9f78-3177b87dc6f9.JPG)

## Ideation Session
We conducted a series of visioning exercises, adapted from design thinking and Lean UX activities. As a team, we played the following visioning "games".

Before we could start these "games" (detailed below), we had to set up some ground rules for the session:

![ideation rules](https://cloud.githubusercontent.com/assets/13038047/8505371/9e22adaa-21b1-11e5-8ead-4badc56faaf1.JPG)

![charter](https://cloud.githubusercontent.com/assets/12210285/8508143/a4af9292-2232-11e5-9da9-8c8decab757e.JPG)
![journey map](https://cloud.githubusercontent.com/assets/12210285/8508144/a4b15794-2232-11e5-88b2-a32364c3bfe7.JPG)
![ideation 5](https://cloud.githubusercontent.com/assets/12210285/8508148/a4b49e2c-2232-11e5-8fa6-949ab24a3013.JPG)
![ideation 4](https://cloud.githubusercontent.com/assets/12210285/8508145/a4b28088-2232-11e5-9233-1de82a6c7007.JPG)
![ideation3](https://cloud.githubusercontent.com/assets/12210285/8508146/a4b312e6-2232-11e5-883a-7611804028cb.JPG)
![ideation 2](https://cloud.githubusercontent.com/assets/12210285/8508149/a4b7c7b4-2232-11e5-892a-9c81726556f4.JPG)
![ideation session](https://cloud.githubusercontent.com/assets/12210285/8508147/a4b4bf2e-2232-11e5-81b8-6aaf4450fef3.JPG)


Everyone agreed to these rules, and one was added along the way. At any point, we were allowed to call out "ELMO" ("Enough Let's Move On") if someone was speaking too much, and we agreed as a group that it would not be rude to do this. 

**(1) Mad Libs Style Brainstorming** - We had a series of question stems and brainstormed individually and in groups to get post-its on the wall with lots of ideas. 

![brainstorming 1](https://cloud.githubusercontent.com/assets/13038047/8505232/8afdffe8-21ae-11e5-9eca-39e8b5ce8621.JPG)
![brainstorming 2](https://cloud.githubusercontent.com/assets/13038047/8505233/8b0afde2-21ae-11e5-866c-7f7d9f037f03.JPG)
![brainstorming](https://cloud.githubusercontent.com/assets/13038047/8505234/8b0d5d12-21ae-11e5-8b5f-4e0bf79459cb.JPG)

We did this for each of several fill-in-the-blank brainstorming stems:

FOR [target customer]
WHO NEEDS [services/features]
UNLIKE [competitors/alternatives]
WE ARE A [business type]
WE PROVIDE [emotional benefit]
WE STAND OUT BY [key differentiator]

As you can see from the photo below, our team's UX analyst set up the room before everyone walked in so that the question stems were on the wall. During the day-long ideation session, we brainstormed each one of these segments, validating with market research in between.

![visioning wall](https://cloud.githubusercontent.com/assets/13038047/8505271/8c43fcda-21af-11e5-9e4d-dfd8700bfbcf.JPG)

**(2) Dot Voting on the Wall** - Once all the ideas were on the wall, we grouped them and voted on the best ones. We had red and green dots for the ones we most agreed with and disagreed with. This enabled us to quickly gauge major trends in the room, and save time by only talking about the items with mixed opinions.  

Based on this dot voting, as a group we chose two distinct customers to possibly target, parents and data scientists:

![dot voting](https://cloud.githubusercontent.com/assets/13038047/8505241/c40c5cf8-21ae-11e5-9554-c9f53daa0a20.JPG)

We conducted market research these items and realized that despite our best hypotheses, the market was not there for these two key target audiences.

![collaboration3](https://cloud.githubusercontent.com/assets/13038047/8505255/0c397b50-21af-11e5-9968-a7823556772f.JPG) 

So we went back to our brainstorming board and discussed several others who might be target audiences.

![brainstorming 3](https://cloud.githubusercontent.com/assets/13038047/8505235/8b0dc054-21ae-11e5-831c-ec778ec0bc25.JPG)

**(3) Persona Sketching** - After voting on the major target audiences, and doing lite market research on whether they would make for a good fit, we sketched personas for the key audiences we hypothesized that we would target

![sketches - personas and journeys](https://cloud.githubusercontent.com/assets/13038047/8505327/d15cd764-21b0-11e5-8888-719859e45a1c.JPG)

**(4) User Stories** - As a group, we determined the top tasks a user would do, and wrote user scribed user stories for those items. [Check out our user stories >](https://github.com/booz-allen-agile-delivery/ads-final/wiki/User-Stories)

**(4) Journey Mapping/Task Analysis** - We drafted journeys for each of these audiences on the websites starting with what they would do when they came to the site. Small groups sketched a journey for each key persona, outlining flows for the hypothesized top tasks. 

![journey mapping - small groups 1](https://cloud.githubusercontent.com/assets/13038047/8505343/260e22f4-21b1-11e5-9f6c-f9cd75b9bae2.JPG)
![journey mapping in small groups](https://cloud.githubusercontent.com/assets/13038047/8505344/2617f982-21b1-11e5-809e-b7f1ede5c0b3.JPG)

Then each small group shared the journeys with the larger group and we discussed each.

![journeys - sharing](https://cloud.githubusercontent.com/assets/13038047/8505352/517fa35e-21b1-11e5-91e7-28066aa6ec39.JPG)

Based on this information, our fill-in-the-blank mad libs-style vision evolved with more thought and research. We were able to write a basic charter for what we were building that hung beside us on the wall throughout the challenge. After our major pivot, this vision did change slightly.

![initial charter](https://cloud.githubusercontent.com/assets/13038047/8505356/6417b394-21b1-11e5-843a-4b5dff61cd3e.JPG)

## Market Research on Persona Groups & Industry Competition 
We conducted market research at numerous steps throughout the process because we wanted to make sure we were delivering something of high value for our target users that would help people taking medications, either directly or indirectly -- something we decided on as a team up front.

For example, our initial design thinking / visioning exercise came up with the hypothesis that we should create an app for parents to understand side effects of their children’s medicine. We conducted market research on this hypothesis and determined that this market is overcrowded, and an app for this persona may not provide enough distinct value. We went back to our sticky tabs, selected other audiences to research. 

At this point, we discussed targeting a general consumer who may need drug comparisons by condition. Our market research however found that sites like Iodine already do this fairly well. We also debated if this was the best use of the FDA data.

## User Interviews
For the items we could not find certain market research for, we turned to user interviews. We hypothesized, for example, that targeting doctors may bring a high degree of value to the consumer indirectly because a patient will likely not use a drug without discussing it with his or her doctor.  We conducted phone-based user interviews with doctors we knew to understand their process in deciding on what medications to prescribe.  They told us about sites they were already using such as UpToDate which worked extremely well for their needs, and because of those interviews we decided that doctors were actually not our target audience, so we went back to the other audiences to refine them further. For general public consumers, we wanted to target health-conscious people of all ages and backgrounds so we chose to go to a LabCorp waiting room in order to chat with users waiting for bloodwork about their goals and needs in a system with medical data. 

![usab testing labcorp front desk](https://cloud.githubusercontent.com/assets/13038047/8505393/fbc73c6e-21b1-11e5-9c84-61767058d0bc.jpg)
![usab testing labcorp participants](https://cloud.githubusercontent.com/assets/13038047/8505394/fbd0f632-21b1-11e5-9089-dd816cc66fe7.jpg)

To understand the geriatric community, we spoke to two senior citizens by phone. We also spoke to two members of the Board of Directors of a local assisted living community, Vantage House: 

![vantage house](https://cloud.githubusercontent.com/assets/13038047/8505405/7ac43ca6-21b2-11e5-835c-a2ff2307e5f5.jpg)

For the advocacy group persona, we phoned the founder of the Hashimoto’s 411 group (which one of our user interviews referenced), and also spoke to two members of the group. Our in-person, moderated usability testing also provided qualitative behavioral data on user goals to be incorporated into the wireframes as well as personas. 

Our user interviews impacted not only our personas, but also our user stories, journey maps, and wireframes. Ultimately these interviews guided what product we were building. We found out that about half of the people we spoke to read labels, and of those people nearly all of them feel mistrusting of the label alone, and for good reason!  Of the top adverse events reported, only a fraction makes it onto medicine labels. To do anything about this big honkin' problem, we needed better data.  And who better to help us with that than the people who need it -- health conscious general public, advocacy groups, etc. Everyone wants to know about side effects, and a small fraction of these people are willing to help make labels more accurate. With crowdsourcing, even a small fraction of do-gooders can make a big difference. Therefore, the goal of our website is ultimately to perform a gap analysis between adverse events data and label data, using crowdsourcing to help give us the proper data to help FDA administrators make drug labels more accurate. 

After our pivot, this was our modified charter:

PHOTO OF FINAL CHARTER

## Personas
We started by hand-sketching our personas and guessing about their needs, goals and journeys. We then learned more about our users through user interviews (in person and by phone) and usability testing. Our personas were living documents that were updated as we learned more. They all had faces and names, and we spoke about them as if they were team members throughout the process. We got to know them them and empathized with them as we designed and coded. Our hand-sketched wireframes were moved into Axure, and were tested and updated in iterative rounds of usability testing.

IMAGE OF BECCA PERSONA

IMAGE OF VIC PERSONA

IMAGE OF ESTER PERSONA

IMAGE OF MATT PERSONA

IMAGE OF HASHI'S GROUP PERSONA

## Wireframing
We started with hand-sketched wireframes on large easel-sized post-it pads on the wall.  

![wireframe sketching on whiteboard](https://cloud.githubusercontent.com/assets/13038047/8505414/ca549d24-21b2-11e5-8f31-c2ff64edec85.jpg)

After iterating sketches and verifying with user stories and personas, we moved the wireframes into a rapid prototyping software, Axure. Our certified usability analyst conducted a heuristic review based on industry best practices and recommended enhancements to the navigation, presentation, content and interaction represented in the wireframe. Through rounds of usability testing and user interviews, we continually updated the wireframe. We shared it with developers and used the Kanban board and our periodic reviews to prioritize functionality to code. While the developers coded core functionality, team members focused on user design continued to talk with users and update wireframes to match recommendations on look, layout and textual elements. 

## Usability Testing
We performed numerous small-scale, iterative rounds of usability testing both in-person and by phone. All of our usability testing was moderated because we were most interested in behavioral, qualitative feedback from our key target audiences. [Our usability testing process >](https://github.com/booz-allen-agile-delivery/ads-final/wiki/Usability-Testing)
